{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model serving & deployment testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This notebook test model deployment using a pre-transformed example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_ID='5909171311854223360' \n",
    "GOOGLE_CLOUD_PROJECT = 'aliz-ml-spec-2022-submission'\n",
    "GOOGLE_CLOUD_REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/assets/vocab_compute_and_apply_vocabulary_1_vocabulary...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/assets/vocab_compute_and_apply_vocabulary_2_vocabulary...\n",
      "\\ [2 files][   53.0 B/   53.0 B]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/assets/vocab_compute_and_apply_vocabulary_3_vocabulary...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/assets/vocab_compute_and_apply_vocabulary_4_vocabulary...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/assets/vocab_compute_and_apply_vocabulary_5_vocabulary...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/assets/vocab_compute_and_apply_vocabulary_vocabulary...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/saved_model.pb...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/variables/variables.data-00000-of-00001...\n",
      "Copying gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn/variables/variables.index...\n",
      "| [9 files][117.7 KiB/117.7 KiB]                                                \n",
      "Operation completed over 9 objects/117.7 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://aliz-ml-spec-2022/demo-1/pipeline_root/taxi-vertex-pipelines/53911330556/taxi-vertex-pipelines-20220621095033/Transform_1699445304064999424/transform_graph/transform_fn transform_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below uses the transform graph output by the Transform component to both preprocess our input data and convert it to the format required by Vertex AI Endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_transform as tft\n",
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_fn(instances):\n",
    "    loaded_transform_model =tft.TFTransformOutput('transform_fn')\n",
    "    transform_layer = loaded_transform_model.transform_features_layer()\n",
    "    raw_data_batch = {\n",
    "    'dropoff_census_tract': tf.constant([ex['dropoff_census_tract'] for ex in instances], dtype=tf.int64),\n",
    "    'TripStartHour': tf.constant([ex['TripStartHour'] for ex in instances], dtype=tf.int64),\n",
    "    'TripStartMinute': tf.constant([ex['TripStartMinute'] for ex in instances], dtype=tf.int64),\n",
    "    'TripStartYear': tf.constant([ex['TripStartYear'] for ex in instances], dtype=tf.int64),\n",
    "    'TripStartMonth': tf.constant([ex['TripStartMonth'] for ex in instances], dtype=tf.int64),\n",
    "    'pickup_census_tract': tf.constant([ex['pickup_census_tract'] for ex in instances], dtype=tf.int64),\n",
    "    'histOneWeek_tripDistance': tf.constant([ex['histOneWeek_tripDistance'] for ex in instances], dtype=tf.float32),\n",
    "    'histOneWeek_tripDuration': tf.constant([ex['histOneWeek_tripDuration'] for ex in instances], dtype=tf.float32),\n",
    "    'historical_tripDuration': tf.constant([ex['historical_tripDuration'] for ex in instances], dtype=tf.float32),\n",
    "    'historical_tripDistance': tf.constant([ex['historical_tripDistance'] for ex in instances], dtype=tf.float32),\n",
    "    'rawDistance': tf.constant([ex['rawDistance'] for ex in instances], dtype=tf.float32),\n",
    "    }\n",
    "    transformed_input = transform_layer(raw_data_batch)\n",
    "    for key in transformed_input:\n",
    "        transformed_input[key] = [transformed_input[key][0][0].numpy().item()]\n",
    "    return transformed_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below is taken from the dataset we have created previously. The expected output is 40.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = {'dropoff_census_tract': [17031980100], 'histOneWeek_tripDistance': [12.215],\n",
    "             'TripStartHour': [16], 'TripStartMinute': [15], 'TripStartYear': [2016],\n",
    "             'histOneWeek_tripDuration': [3000.0],\n",
    "             'historical_tripDuration': [2954.0487804878048], 'pickup_census_tract': [17031081500],\n",
    "             'TripStartMonth': [4], 'historical_tripDistance': [12.332439024390244],\n",
    "             'rawDistance': [0.16400959606286278]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:01:59.309099: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n",
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n",
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "prediction: [43.3953552]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "\n",
    "# The AI Platform services require regional API endpoints.\n",
    "client_options = {\n",
    "    'api_endpoint': GOOGLE_CLOUD_REGION + '-aiplatform.googleapis.com'\n",
    "    }\n",
    "# Initialize client that will be used to create and send requests.\n",
    "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "\n",
    "\n",
    "instances = [instance]\n",
    "transformed_instance = preprocess_fn(instances)\n",
    "\n",
    "endpoint = client.endpoint_path(\n",
    "    project=GOOGLE_CLOUD_PROJECT,\n",
    "    location=GOOGLE_CLOUD_REGION,\n",
    "    endpoint=ENDPOINT_ID,\n",
    ")\n",
    "response = client.predict(endpoint=endpoint, instances=[transformed_instance])\n",
    "print('prediction:', response.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction of 43.4 we get back is fairly close to the expected 40.5 from the example"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
