{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model hyper-parameter tuning & evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This notebook runs the hyperparameter tuning of the production model.\n",
    "\n",
    "The production model is a deep & wide neural net regressor.\n",
    "<br>For the wide part of the model, the following features are used:\n",
    "- `TripStartYear`\n",
    "- `TripStartMonth`\n",
    "- `TripStartDay`\n",
    "- `TripStartHour`\n",
    "- `TripStartMinute`\n",
    "- `month_day`: feature cross of `TripStartMonth` & `TripStartDay`\n",
    "- `day_hour`: feature cross of `TripStartDay` & `TripStartHour`\n",
    "\n",
    "As for the deep part of the model, the following features are used:\n",
    "- `historical_tripDuration`\n",
    "- `histOneWeek_tripDuration`\n",
    "- `historical_tripDistance`\n",
    "- `histOneWeek_tripDistance`\n",
    "- `rawDistance`\n",
    "- `pickup_census_tract` embedded\n",
    "- `dropoff_census_tract` embedded\n",
    "\n",
    "The hyperparameters to tune are:\n",
    "- `batch-size` of the optimisation method, amongst the discrete set: `[64, 128, 256, 512]`\n",
    "- `hidden-units` of the deep part of the model amongst the discrete set: `[\"100,50,25,5\", \"256,128,32,8\"]`\n",
    "\n",
    "__RMSE__ is used as the metric to evaluate for the hypertuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: chicago_taxi_ml_hypertune_model_20191010_110510\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [chicago_taxi_ml_hypertune_model_20191010_110510] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe chicago_taxi_ml_hypertune_model_20191010_110510\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs chicago_taxi_ml_hypertune_model_20191010_110510\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "sh hyperopt.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [AI Platform job details](https://console.cloud.google.com/ai-platform/jobs/chicago_taxi_ml_hypertune_model_20191010_110510/charts/cpu?project=szilard-kalosi-sandbox),\n",
    "\n",
    "the best model trained is the __Trial ID 5__ with the following hyperparameter values:\n",
    "- `batch-size` = 256\n",
    "- `hidden-units` = \"256,128,32,8\"\n",
    "\n",
    "First, let's train the deep & wide model with such hyperparameter values.\n",
    "Then we will evaluate the trained model with [Tensorflow Model Analysis](https://www.tensorflow.org/tfx/model_analysis/get_started).\n",
    "<br>More specifically, TFMA runs the model on the test set for final evaluation and provides a visual interface to show its predictive weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: chicago_taxi_ml_train_model_20191010_124441\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [chicago_taxi_ml_train_model_20191010_124441] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe chicago_taxi_ml_train_model_20191010_124441\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs chicago_taxi_ml_train_model_20191010_124441\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "TF_TRAINING_OUTPUT=\"gs://szilard_aliz_sandbox/pierre_tasks/demo1/model_optimised\"\n",
    "TFDV_OUTPUT=\"gs://szilard_aliz_sandbox/pierre_tasks/demo1/tfdv\"\n",
    "TFT_OUTPUT=\"gs://szilard_aliz_sandbox/pierre_tasks/demo1/tft\"\n",
    "\n",
    "gcloud ai-platform jobs submit training \\\n",
    "\"chicago_taxi_ml_train_model_$(date +%Y%m%d_%H%M%S)\" \\\n",
    "--region us-central1 \\\n",
    "--package-path trainer \\\n",
    "--module-name trainer.task \\\n",
    "--job-dir $TF_TRAINING_OUTPUT \\\n",
    "--config train.yaml \\\n",
    "-- --tfdv-output $TFDV_OUTPUT \\\n",
    "--tft-output $TFT_OUTPUT \\\n",
    "--train-size 56948734 \\\n",
    "--train-epochs 2 \\\n",
    "--throttle-secs 60 \\\n",
    "--batch-size 256 \\\n",
    "--hidden-units \"256,128,32,8\" \\\n",
    "--eval-steps 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TFMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting distributed TFMA computation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python2.7/site-packages/apache_beam/__init__.py:84: UserWarning: You are using Apache Beam with Python 2. New releases of Apache Beam will soon support Python 3 only.\n",
      "  'You are using Apache Beam with Python 2. '\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python2.7/site-packages/tensorflow_model_analysis/types.py:36: The name tf.SparseTensorValue is deprecated. Please use tf.compat.v1.SparseTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From model_analysis/analyse_model.py:66: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From model_analysis/analyse_model.py:66: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From model_analysis/analyse_model.py:52: The name tf.gfile.ListDirectory is deprecated. Please use tf.io.gfile.listdir instead.\n",
      "\n",
      "/home/jupyter/.local/lib/python2.7/site-packages/tensorflow_model_analysis/slicer/slicer.py:407: BeamDeprecationWarning: RemoveDuplicates is deprecated since 2.12. Use Distinct instead.\n",
      "  | 'IncrementCounter' >> beam.Map(increment_counter))\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "echo Starting distributed TFMA computation...\n",
    "\n",
    "JOB_ID=\"demo1-tfma-model-optimised-$(date +%Y%m%d-%H%M%S)\"\n",
    "TFMA_OUTPUT=\"gs://szilard_aliz_sandbox/pierre_tasks/demo1/tfma_model_optimised\"\n",
    "TRAINED_MODEL_LOC=\"gs://szilard_aliz_sandbox/pierre_tasks/demo1/model_optimised\"\n",
    "TFDV_OUTPUT=\"gs://szilard_aliz_sandbox/pierre_tasks/demo1/tfdv\"\n",
    "TEMP_PATH=$TFMA_OUTPUT/tmp/\n",
    "MYPROJECT=$(gcloud config list --format 'value(core.project)' 2>/dev/null)\n",
    "\n",
    "python model_analysis/analyse_model.py \\\n",
    "    --tfma-output $TFMA_OUTPUT \\\n",
    "    --trained-model-loc $TRAINED_MODEL_LOC \\\n",
    "    --tfdv-output $TFDV_OUTPUT \\\n",
    "    --project $MYPROJECT \\\n",
    "    --region us-central1 \\\n",
    "    --temp_location $TEMP_PATH \\\n",
    "    --job_name $JOB_ID \\\n",
    "    --save_main_session \\\n",
    "    --setup_file model_analysis/setup.py \\\n",
    "    --runner DataflowRunner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run, TFMA needs notebook extensions.\n",
    "<br>To enable such extensions, keep in mind to switch on AI Platform from standard Jupyterlab to Jupyter notebook classic version.\n",
    "<br>To do so, go to `Help > Launch Classic Notebook`.\n",
    "\n",
    "Furthermore TFMA visuals cannot be saved neither in the notebook nor even in an HTML version.\n",
    "<br>We need to re-run the cell everytime we want to visualize the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python2.7/site-packages/apache_beam/__init__.py:84: UserWarning: You are using Apache Beam with Python 2. New releases of Apache Beam will soon support Python 3 only.\n",
      "  'You are using Apache Beam with Python 2. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFMA version: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "print('TFMA version: {}'.format(tfma.version.VERSION_STRING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python2.7/site-packages/tensorflow_model_analysis/writers/metrics_and_plots_serialization.py:46: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "train_result = tfma.load_eval_result(output_path='gs://szilard_aliz_sandbox/pierre_tasks/demo1/tfma_model_optimised/train/')\n",
    "eval_result = tfma.load_eval_result(output_path='gs://szilard_aliz_sandbox/pierre_tasks/demo1/tfma_model_optimised/eval/')\n",
    "test_result = tfma.load_eval_result(output_path='gs://szilard_aliz_sandbox/pierre_tasks/demo1/tfma_model_optimised/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e17a4cf20b7450b8faa0e034f45f4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "U2xpY2luZ01ldHJpY3NWaWV3ZXIoY29uZmlnPXsnd2VpZ2h0ZWRFeGFtcGxlc0NvbHVtbic6IDF9LCBkYXRhPVt7J21ldHJpY3MnOiB7dSdsYWJlbC9tZWFuJzogeydkb3VibGVWYWx1ZSc6IDHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(train_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937594be5e854c1daba6db81cfc3c312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "U2xpY2luZ01ldHJpY3NWaWV3ZXIoY29uZmlnPXsnd2VpZ2h0ZWRFeGFtcGxlc0NvbHVtbic6IDF9LCBkYXRhPVt7J21ldHJpY3MnOiB7dSdsYWJlbC9tZWFuJzogeydkb3VibGVWYWx1ZSc6IDHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e96c790f24e4043b0402ef2e7fbc4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "U2xpY2luZ01ldHJpY3NWaWV3ZXIoY29uZmlnPXsnd2VpZ2h0ZWRFeGFtcGxlc0NvbHVtbic6IDF9LCBkYXRhPVt7J21ldHJpY3MnOiB7dSdsYWJlbC9tZWFuJzogeydkb3VibGVWYWx1ZSc6IDHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4656dda0344b00b98d709e6c1b3019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "U2xpY2luZ01ldHJpY3NWaWV3ZXIoY29uZmlnPXsnd2VpZ2h0ZWRFeGFtcGxlc0NvbHVtbic6IDF9LCBkYXRhPVt7J21ldHJpY3MnOiB7dSdsYWJlbC9tZWFuJzogeydkb3VibGVWYWx1ZSc6IDHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(test_result, slicing_column='TripStartMonth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f439241d2844a2bdab6879c55fc7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "U2xpY2luZ01ldHJpY3NWaWV3ZXIoY29uZmlnPXsnd2VpZ2h0ZWRFeGFtcGxlc0NvbHVtbic6IDF9LCBkYXRhPVt7J21ldHJpY3MnOiB7dSdsYWJlbC9tZWFuJzogeydkb3VibGVWYWx1ZSc6IDHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(test_result, slicing_column='TripStartDay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a conclusion, there are no noticeable discrepancy in the model performance.\n",
    "\n",
    "Here are the diverse model performances in terms of __RMSE__:\n",
    "- training: __2.511__\n",
    "- evaluation: __2.52__\n",
    "- test: __2.624__\n",
    "\n",
    "The model behaves well without any overfitting.\n",
    "<br>Furthermore, either for training, evaluation or test, the model's performance is also very stable when partitioned with the different slices of `TripStartMonth` & `TripStartDay` - except for __Saturday__ where performance (in __RMSE__) drops from __~2.57__ to __3.045__.\n",
    "\n",
    "Compared to the baseline model, the performance improvement on the holdout test is about __9.3%__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
